{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:64,expandable_segments:True\"\n",
        "\n",
        "import random\n",
        "import json\n",
        "import numpy as np\n",
        "import torch\n",
        "from itertools import combinations\n",
        "from collections import defaultdict\n",
        "\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import (\n",
        "    AutoTokenizer, AutoModelForMaskedLM, DataCollatorForLanguageModeling,\n",
        "    Trainer, TrainingArguments, EarlyStoppingCallback\n",
        ")\n",
        "from sentence_transformers import SentenceTransformer, models, InputExample, losses, evaluation\n",
        "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3hSQv4EgVUlh",
        "outputId": "d46aa373-501d-43db-9b92-df43001f1af4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
            "Some weights of XLMRobertaForMaskedLM were not initialized from the model checkpoint at sentence-transformers/paraphrase-multilingual-mpnet-base-v2 and are newly initialized: ['lm_head.bias', 'lm_head.decoder.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "SEED = 42\n",
        "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print(\"torch.cuda.is_available():\", torch.cuda.is_available())\n",
        "\n",
        "CORPUS_FILE = \"/content/text_corpus_grls_rlsnet.txt\"\n",
        "SYN_DATA_FILE_LIST = [\n",
        "    \"/content/clusters_2025_08_20_15.json\",\n",
        "    \"/content/clusters_2025_08_20_200.json\",\n",
        "    \"/content/clusters_2025_08_20_400.json\",\n",
        "    \"/content/clusters_synosym_dict.json\"\n",
        "]\n",
        "\n",
        "OUTPUT_DIR = \"trained_synonym_model\"\n",
        "\n",
        "# 1. Domain-Adaptive Pretraining (MLM) с короткими последовательностями\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, texts, tokenizer, max_len=128):\n",
        "        toks = tokenizer(texts, truncation=True, padding=\"max_length\",\n",
        "                         max_length=max_len, return_tensors=\"pt\")\n",
        "        self.input_ids = toks[\"input_ids\"]\n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "    def __getitem__(self, idx):\n",
        "        return {\"input_ids\": self.input_ids[idx]}\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\")\n",
        "\n",
        "with open(CORPUS_FILE, encoding=\"utf-8\") as f:\n",
        "    lines = [l.strip() for l in f if len(l.split()) > 3]\n",
        "texts = list(set(lines))\n",
        "\n",
        "dataset = TextDataset(texts, tokenizer, max_len=128)\n",
        "data_collator = DataCollatorForLanguageModeling(tokenizer, mlm=True, mlm_probability=0.15)\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"dapt_mlm\",\n",
        "    overwrite_output_dir=True,\n",
        "    per_device_train_batch_size=4,\n",
        "    gradient_accumulation_steps=4,\n",
        "    num_train_epochs=3,\n",
        "    fp16=True,\n",
        "    save_steps=5000,\n",
        "    logging_steps=2000,\n",
        "    learning_rate=3e-5\n",
        ")\n",
        "\n",
        "model = AutoModelForMaskedLM.from_pretrained(\"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=dataset\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "id": "Lht0yAQBi46r",
        "outputId": "ea9d64ad-0ce0-480a-ea2c-a1367829861a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1161' max='1161' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1161/1161 20:50, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "('dapt_mlm/tokenizer_config.json',\n",
              " 'dapt_mlm/special_tokens_map.json',\n",
              " 'dapt_mlm/sentencepiece.bpe.model',\n",
              " 'dapt_mlm/added_tokens.json',\n",
              " 'dapt_mlm/tokenizer.json')"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.train()\n",
        "model.save_pretrained(\"dapt_mlm\")\n",
        "tokenizer.save_pretrained(\"dapt_mlm\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kMACh3pae9tL"
      },
      "outputs": [],
      "source": [
        "# --- Шаг 2: подготовка примеров ---\n",
        "pos_pairs = []\n",
        "neg_pairs = []\n",
        "\n",
        "for filename in SYN_DATA_FILE_LIST:\n",
        "    with open(filename, 'r', encoding=\"utf-8\") as f:\n",
        "        clusters = json.load(f)[\"clusters\"]\n",
        "\n",
        "\n",
        "    for cluster_data in clusters.values():\n",
        "        grouped = defaultdict(list)\n",
        "        all_labels = []\n",
        "\n",
        "        for label, group_id in cluster_data[\"labels\"]:\n",
        "            all_labels.append((label, group_id))\n",
        "            if group_id is not None:\n",
        "                grouped[group_id].append(label)\n",
        "\n",
        "        # Положительные пары — внутри одного подмножества с одинаковыми group_id ≠ None\n",
        "        for group in grouped.values():\n",
        "            if len(group) > 1:\n",
        "                pos_pairs.extend(combinations(group, 2))\n",
        "\n",
        "        # Отрицательные пары — между разными номерами внутри кластера\n",
        "        group_ids = list(grouped.keys())\n",
        "        for i in range(len(group_ids)):\n",
        "            for j in range(i + 1, len(group_ids)):\n",
        "                group_a = grouped[group_ids[i]]\n",
        "                group_b = grouped[group_ids[j]]\n",
        "                neg_pairs.extend((a, b) for a in group_a for b in group_b)\n",
        "\n",
        "        # Отрицательные пары для всех с null\n",
        "        null_items = [label for label, gid in all_labels if gid is None]\n",
        "        non_null_items = [label for label, gid in all_labels if gid is not None]\n",
        "\n",
        "        for null_label in null_items:\n",
        "            for other_label in non_null_items:\n",
        "                neg_pairs.append((null_label, other_label))\n",
        "\n",
        "# Удаление дубликатов\n",
        "pos_pairs = list(set(pos_pairs))\n",
        "neg_pairs = list(set(neg_pairs) - set(pos_pairs))\n",
        "\n",
        "# Балансировка\n",
        "random.shuffle(neg_pairs)\n",
        "neg_pairs = neg_pairs[:len(pos_pairs)]\n",
        "\n",
        "examples = [InputExample(texts=[a, b], label=1.0) for a, b in pos_pairs] + \\\n",
        "           [InputExample(texts=[a, b], label=0.0) for a, b in neg_pairs]\n",
        "random.shuffle(examples)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cW-xCBm_Yg7V"
      },
      "outputs": [],
      "source": [
        "# Деление на тренировочную, валидационную и тестовую выборки\n",
        "n = len(examples)\n",
        "train_ex = examples[:int(0.8 * n)]\n",
        "val_ex   = examples[int(0.8 * n):int(0.9 * n)]\n",
        "test_ex  = examples[int(0.9 * n):]\n",
        "\n",
        "train_loader = DataLoader(train_ex, shuffle=True, batch_size=4, collate_fn=lambda batch: batch)\n",
        "val_loader   = DataLoader(val_ex, shuffle=False, batch_size=8, collate_fn=lambda batch: batch)\n",
        "test_loader  = DataLoader(test_ex, shuffle=False, batch_size=8, collate_fn=lambda batch: batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 524,
          "referenced_widgets": [
            "f5b69ae3f2844a2db179e6097abb7c7d",
            "3574fce819fa427bb8b87961b672d469",
            "83a3446e8d0d47d38f62c00bca3df43c",
            "e0ba9b7989e84a148324d4b089253b9c",
            "3ddf47abc19b4b6faf9fe1376b531665",
            "65c29ebddfc946729153290a0949c565",
            "596a574a4373422a9bea1ab9988cd20d",
            "6e84f7e9f76d4b40a4fd334cffa1c2b6",
            "0a49f1af2138406685c532ac075a76c4",
            "5bdae3d1b1a24bb0961fca4773784c2a",
            "4cb79c6dae9b4ffc8e7a78348611a006"
          ]
        },
        "id": "N4J2tyfEq6wP",
        "outputId": "0cfb23a7-5cc6-44f1-f649-04803df8f017"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at dapt_mlm and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f5b69ae3f2844a2db179e6097abb7c7d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2580' max='2580' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2580/2580 12:01, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Val Cosine Accuracy</th>\n",
              "      <th>Val Cosine Accuracy Threshold</th>\n",
              "      <th>Val Cosine F1</th>\n",
              "      <th>Val Cosine F1 Threshold</th>\n",
              "      <th>Val Cosine Precision</th>\n",
              "      <th>Val Cosine Recall</th>\n",
              "      <th>Val Cosine Ap</th>\n",
              "      <th>Val Cosine Mcc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>258</td>\n",
              "      <td>No log</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.961240</td>\n",
              "      <td>0.695152</td>\n",
              "      <td>0.964029</td>\n",
              "      <td>0.695152</td>\n",
              "      <td>0.957143</td>\n",
              "      <td>0.971014</td>\n",
              "      <td>0.971978</td>\n",
              "      <td>0.922129</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>516</td>\n",
              "      <td>0.009200</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.937984</td>\n",
              "      <td>0.797684</td>\n",
              "      <td>0.943662</td>\n",
              "      <td>0.596288</td>\n",
              "      <td>0.917808</td>\n",
              "      <td>0.971014</td>\n",
              "      <td>0.974740</td>\n",
              "      <td>0.876537</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>774</td>\n",
              "      <td>0.009200</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.945736</td>\n",
              "      <td>0.908180</td>\n",
              "      <td>0.948148</td>\n",
              "      <td>0.908180</td>\n",
              "      <td>0.969697</td>\n",
              "      <td>0.927536</td>\n",
              "      <td>0.979386</td>\n",
              "      <td>0.892265</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1032</td>\n",
              "      <td>0.002000</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.945736</td>\n",
              "      <td>0.865521</td>\n",
              "      <td>0.948148</td>\n",
              "      <td>0.865521</td>\n",
              "      <td>0.969697</td>\n",
              "      <td>0.927536</td>\n",
              "      <td>0.980088</td>\n",
              "      <td>0.892265</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1290</td>\n",
              "      <td>0.002000</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.937984</td>\n",
              "      <td>0.888971</td>\n",
              "      <td>0.940299</td>\n",
              "      <td>0.888971</td>\n",
              "      <td>0.969231</td>\n",
              "      <td>0.913043</td>\n",
              "      <td>0.979718</td>\n",
              "      <td>0.877593</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1548</td>\n",
              "      <td>0.001000</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.937984</td>\n",
              "      <td>0.866359</td>\n",
              "      <td>0.942029</td>\n",
              "      <td>0.757279</td>\n",
              "      <td>0.942029</td>\n",
              "      <td>0.942029</td>\n",
              "      <td>0.983018</td>\n",
              "      <td>0.875362</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1806</td>\n",
              "      <td>0.001000</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.945736</td>\n",
              "      <td>0.700096</td>\n",
              "      <td>0.950355</td>\n",
              "      <td>0.700096</td>\n",
              "      <td>0.930556</td>\n",
              "      <td>0.971014</td>\n",
              "      <td>0.984847</td>\n",
              "      <td>0.891566</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2064</td>\n",
              "      <td>0.000600</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.930233</td>\n",
              "      <td>0.828539</td>\n",
              "      <td>0.937931</td>\n",
              "      <td>0.559080</td>\n",
              "      <td>0.894737</td>\n",
              "      <td>0.985507</td>\n",
              "      <td>0.983349</td>\n",
              "      <td>0.863940</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2322</td>\n",
              "      <td>0.000600</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.937984</td>\n",
              "      <td>0.776559</td>\n",
              "      <td>0.942029</td>\n",
              "      <td>0.776559</td>\n",
              "      <td>0.942029</td>\n",
              "      <td>0.942029</td>\n",
              "      <td>0.982385</td>\n",
              "      <td>0.875362</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2580</td>\n",
              "      <td>0.000500</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.937984</td>\n",
              "      <td>0.771797</td>\n",
              "      <td>0.942029</td>\n",
              "      <td>0.771797</td>\n",
              "      <td>0.942029</td>\n",
              "      <td>0.942029</td>\n",
              "      <td>0.981244</td>\n",
              "      <td>0.875362</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sentence_transformers/util/tensor.py:28: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:253.)\n",
            "  a = torch.tensor(a)\n"
          ]
        }
      ],
      "source": [
        "# --- Шаг 3: SentenceTransformer из DAPT-чекпоинта ---\n",
        "transformer = models.Transformer(\"dapt_mlm\", max_seq_length=128)\n",
        "pooling     = models.Pooling(transformer.get_word_embedding_dimension(),\n",
        "                             pooling_mode_mean_tokens=True)\n",
        "st_model    = SentenceTransformer(modules=[transformer, pooling], device=device)\n",
        "\n",
        "# жёсткие негативы\n",
        "def mine_hard(batch, model, k=1):\n",
        "    texts = [t for ex in batch for t in ex.texts]\n",
        "    emb   = model.encode(texts, convert_to_tensor=True, batch_size=4)\n",
        "    emb   = torch.nn.functional.normalize(emb, dim=1)\n",
        "    sims  = emb @ emb.T\n",
        "    hard  = []\n",
        "    for i in range(0, len(texts), 2):\n",
        "        row = sims[i].clone()\n",
        "        row[i] = row[i+1] = -1\n",
        "        neg_ids = torch.topk(row, k).indices.tolist()\n",
        "        for j in neg_ids:\n",
        "            hard.append(InputExample(texts=[texts[i], texts[j]], label=0.0))\n",
        "    return hard\n",
        "\n",
        "class HardNegDataset(Dataset):\n",
        "    def __init__(self, examples, model):\n",
        "        self.examples = examples\n",
        "        self.model    = model\n",
        "    def __len__(self):\n",
        "        return len(self.examples)\n",
        "    def __getitem__(self, idx):\n",
        "        return self.examples[idx]\n",
        "    def collate(self, batch):\n",
        "        return batch + mine_hard(batch, self.model)\n",
        "\n",
        "hard_ds = HardNegDataset(train_ex, st_model)\n",
        "train_loader_hard = DataLoader(\n",
        "    hard_ds,\n",
        "    shuffle=True,\n",
        "    batch_size=4,\n",
        "    collate_fn=lambda batch: hard_ds.collate(batch)\n",
        ")\n",
        "\n",
        "# Контрастное обучение\n",
        "train_loss = losses.ContrastiveLoss(model=st_model)\n",
        "evaluator  = evaluation.BinaryClassificationEvaluator.from_input_examples(\n",
        "    val_ex, name=\"val\", show_progress_bar=False\n",
        ")\n",
        "\n",
        "st_model.fit(\n",
        "    train_objectives=[(train_loader_hard, train_loss)],\n",
        "    evaluator=evaluator,\n",
        "    epochs=10,\n",
        "    evaluation_steps=len(train_loader_hard),\n",
        "    warmup_steps=50,\n",
        "    use_amp=True,\n",
        "    output_path=OUTPUT_DIR,\n",
        "    optimizer_params={'lr': 2e-5}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SmfFMPUFq36r",
        "outputId": "3d6a9b1a-ec44-42ae-b8ea-a3584d725fb5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test metrics: {'precision': 1.0, 'recall': 0.9538461538461539, 'f1': 0.9763779527559056, 'roc_auc': np.float64(0.9911057692307693)}\n"
          ]
        }
      ],
      "source": [
        "# --- Шаг 4: оценка ---\n",
        "def evaluate(loader, model, thr=0.92):\n",
        "    labels, scores = [], []\n",
        "    for batch in loader:\n",
        "        t1 = [ex.texts[0] for ex in batch]\n",
        "        t2 = [ex.texts[1] for ex in batch]\n",
        "        e1 = model.encode(t1, convert_to_tensor=True, batch_size=4)\n",
        "        e2 = model.encode(t2, convert_to_tensor=True, batch_size=4)\n",
        "        sim = torch.nn.functional.cosine_similarity(e1, e2).cpu().numpy()\n",
        "        labels.extend([ex.label for ex in batch])\n",
        "        scores.extend(sim.tolist())\n",
        "    preds = [1 if s >= thr else 0 for s in scores]\n",
        "    p, r, f, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
        "    auc       = roc_auc_score(labels, scores)\n",
        "    return {'precision': p, 'recall': r, 'f1': f, 'roc_auc': auc}\n",
        "\n",
        "best = SentenceTransformer(OUTPUT_DIR, device=device)\n",
        "print(\"Test metrics:\", evaluate(test_loader, best))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cW5OS49Oe9Va"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0a49f1af2138406685c532ac075a76c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3574fce819fa427bb8b87961b672d469": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_65c29ebddfc946729153290a0949c565",
            "placeholder": "​",
            "style": "IPY_MODEL_596a574a4373422a9bea1ab9988cd20d",
            "value": "Computing widget examples:   0%"
          }
        },
        "3ddf47abc19b4b6faf9fe1376b531665": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "4cb79c6dae9b4ffc8e7a78348611a006": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "596a574a4373422a9bea1ab9988cd20d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5bdae3d1b1a24bb0961fca4773784c2a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65c29ebddfc946729153290a0949c565": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e84f7e9f76d4b40a4fd334cffa1c2b6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83a3446e8d0d47d38f62c00bca3df43c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e84f7e9f76d4b40a4fd334cffa1c2b6",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0a49f1af2138406685c532ac075a76c4",
            "value": 1
          }
        },
        "e0ba9b7989e84a148324d4b089253b9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5bdae3d1b1a24bb0961fca4773784c2a",
            "placeholder": "​",
            "style": "IPY_MODEL_4cb79c6dae9b4ffc8e7a78348611a006",
            "value": " 0/1 [00:00&lt;?, ?example/s]"
          }
        },
        "f5b69ae3f2844a2db179e6097abb7c7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3574fce819fa427bb8b87961b672d469",
              "IPY_MODEL_83a3446e8d0d47d38f62c00bca3df43c",
              "IPY_MODEL_e0ba9b7989e84a148324d4b089253b9c"
            ],
            "layout": "IPY_MODEL_3ddf47abc19b4b6faf9fe1376b531665"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
